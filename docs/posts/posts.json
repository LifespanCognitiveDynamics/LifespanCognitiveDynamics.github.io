[
  {
    "path": "posts/2025-06-30-CODEC_Classroom_Assessment/",
    "title": "From idea to reality",
    "description": "Classroom ecological momentary assessment",
    "author": [
      {
        "name": "Emma Meeussen",
        "url": {}
      }
    ],
    "date": "2025-06-30",
    "categories": [],
    "contents": "\n\n\n\nStudying cognitive variability in young children is both fun and challenging. If you were to dive into the original plans for CODEC, you would find that Rogier’s intention was to use the VEKTOR platform for collecting behavioral data in five cognitive domains using tablets. We kept the tablets, but VEKTOR was soon replaced due to its incompatibility with our standards for data management. The new platform of choice was m-Path and so one of the project’s new deliverables became to create a set of cognitive tests, freely usable by other researchers.\nAfter 1+ year of tweaking, piloting and retesting, the official m-Path manual now describes 4 of the CODEC tasks (all except the vocabulary test) under the accurate banner of ‘Cool stuff’: whac-a-mole (a simple response time task), fluid reasoning, spatial working memory, and exploration tasks. Creating a free m-Path account will give you access to the tasks.\nOf course, the proof of the pudding is in the eating, and in November 2024 it was time for our most important test: bringing 60 tablets into classrooms full of 7-year-olds to see how they would react. Before any games had even been played, this proved rewarding. The mere mention of tablets had many children burst out in cheers.\nIn preparation for the first testing sessions, we had made sure to create scripted instructions, explaining step by step what would happen during the test week. We even practiced the instructions on some of our (>7 year old) lab members. Note: the attention span of a group of 7-year-olds is shorter than you think, even when you expect it to be shorter than you think. Since we tested two classes in a row, we could immediately incorporate some tweaks for a faster routine into the next session. It was fun to see how the children reacted, and how quickly we adapted to their reactions and to our new role as instructors.\nA few other things that struck us during those first weeks were the massive developmental leaps children take in a year, what a hard task (vocabulary) does to morale, how much help a teacher can be in keeping order, and how cute kids are. We did see some differences in how children reacted to the games, but I was most interested in the matrix reasoning task. Some children were surprisingly motivated by the puzzle element, others demotivated by their initial lack of understanding, followed by relief when they ‘got’ it. I definitely feel like this task elicited the strongest reactions and I’m happy that the Open Matrices Stimuli Set (OMSS) project is further expanding its user possibilities.\nIn January, March and April of this year, we continued testing at three other schools. By the end of April, we had settled into a comfortable routine involving meeting new kids and their teachers every Monday, managing tablet logistics (moving 60 tablets distributed over 6 boxes from one school to the other and back again two weeks later, and do all these boxes fit into this small rented car?) and evaluating the data quality.\nRight now, we’ve collected data for 261 children, equaling ~170.000 trials. We are still recruiting schools for the first wave, and simultaneously preparing for the second wave in the first school. Be sure to check out our other blogs post for more classroom experiences!\n\n\n\n",
    "preview": "posts/2025-06-30-CODEC_Classroom_Assessment/CODEC_Classroom.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2025-05-01-CODEC_GuestLectures/",
    "title": "Guest lectures by the CODEC team?",
    "description": "Loads of questions, various fun experiments and even some answers",
    "author": [
      {
        "name": "Feline van Aagten & Eric Fleischer",
        "url": {}
      }
    ],
    "date": "2025-05-01",
    "categories": [],
    "contents": "\n\n\n\nAs a big thank you to the participating classes in the CODEC project, we offer guest lectures on various topics. We developed our own CODEC-teaching packages: one on being a scientist, one on senses and one on cognition. The lessons are a nice mix between theory and practice, and are freely available on the CODEC website (so feel free to take a look!). In all lessons we invite children to discuss what they already know about the topic and start from there. After we’ve gaged the children’s knowledge we build up a theoretical framework in which we create space for thinking and for asking questions. We keep the children’s age in mind and adapt to what they are capable of. For example, in the higher grades we ask more questions about why they think certain phenomena occur and whether they can think of logical explanations for their classmates’ questions before answering ourselves. In the younger classes, we keep the explanation more concise and help out some more!\nTo stimulate the integration of knowledge, we incorporate small experiments in which the children can experience for themselves how science works. This way, they learn to answer their questions about the world by doing their own research. We start off with a research question, followed by an “experimental” set-up. We ask the kids to perform the task, take measurements and write down their findings in groups. For example, we let the children couple 3D printed brains of various animals to the corresponding owner of the brain. Another example is throwing sandbags as close to a target to find out whether that is easier with your eyes open or shut. After the experiments we go through their findings together, discuss differences between groups and try to find an explanation. Some kids thought of interesting and creative reasons for the outcomes which actually surprised us, and were very possible. We always finish the experiment by asking what went well, what was more difficult and could be improved upon. In this way kids cycle through all the phases of the scientific process in a playful manner. Everyone can be a scientist! We’ve already heard some might want to become our colleagues in the future.\n\n\n\nIn our experience the children participate actively in our lessons, ask lots of interesting questions and even some critical ones. Some kids for example asked us how the brain actually remembers all of its experiences. Another asked us why we are able to smell. Immediately a hand shot into the air. A classmate eagerly responded that it was probably so that we can smell smoke when there is fire. Other kids were interested in how seeing works and why some kids have to wear glasses. It was clear that we are teaching things to little scientists already, as the stream of questions was endless. Of course we could not answer all the questions, but we explain that a lot can be discovered by doing small experiments like the ones in the guest lecture.\nThe children welcomed the exercises with loads of excitement. This behaviour could best be described by “hyperthousiasm”. Getting them back into the classroom after the experiments turned out to be quite the challenge, as most of them insisted on doing more of the experiments. Unfortunately, the time didn’t allow us extra experiments. Fortunately, they did come back into the classroom and discussed their findings with us. They even gave us feedback in the end. One class wanted to end the guest lecture with their tips and tops for us, which we willingly accepted. According to them we explained the subjects thoroughly and answered their questions well. We thanked the class and went back to Trigon with a great feeling and hope for many more guest lectures to come!\n\n\n\n",
    "preview": "posts/2025-05-01-CODEC_GuestLectures/GuestLecture4.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-10-31-Elections/",
    "title": "Bad night or beginning of the end?",
    "description": "On the American presidential elections and cognitive functioning",
    "author": [
      {
        "name": "Jessica Schaaf",
        "url": {}
      }
    ],
    "date": "2024-10-31",
    "categories": [],
    "contents": "\n\n\n\nWith the American presidential elections coming up, there is a lot to do about the cognitive functioning of the presidential candidates. In the months before Joe Biden dropped out of the presidential race, he for example forgot when he served as vice president and mixed up names of world leaders. This made people wonder whether he was capable of leading a world nation for another four years – what if a dip in performance comes at a crucial time? Recently, similar concerns have been raised about Donald Trump, with him referring to non-existing movies and misnaming the current president. Concerning… one may think… the beginning of the end? But how do you distinguish between “just having a bad night” (known as fluctuations) and actual cognitive decline?\nTo answer this question, it is necessary to understand what is normal, especially for people of Biden’s (81) and Trump’s (78) age. From science, we know that cognitive abilities, like your memory, fluctuate over time. One day you easily remember where you put that shirt, whereas the other day you cannot find your keys. How you perform on a given day depends on many things, including your mood, how you slept, and stress levels. When you feel bad or when you are sleep deprived, like Biden suggested after one of his criticized debates, you likely perform worse. We also know that as you age, your brain transmits information less efficiently. This in turn leads to more fluctuations in cognitive performance with age, alongside normal cognitive decline.\nSo, when should we worry?\nOnly when an individual shows signs of cognitive decline for longer periods of time and when this decline is faster than in other individuals of the same age. By frequent cognitive testing–measuring cognitive functioning for a longer period of time–you are better able to assess whether bad days are followed by better days, how somebody functions generally, and which factors may cause bad days (such as poor sleep, less exercise than normal or stress).\n\nThe figure above illustrates the necessity of frequent testing. It shows hypothetical data for two individuals for whom cognitive functioning was measured from age 50 to 90. The blue individual shows substantial fluctuations across age. At some ages, their cognitive functioning is relatively good (for example at age 54 or 80), whereas at other ages, it is relatively bad (for example at age 74). Yet, looking at their overall functioning across age, it fluctuates around a stable average, indicating little to no cognitive decline. The red individual, on the other hand, shows clear cognitive decline, with much worse cognitive functioning at age 90 than at age 50. If we would take a snapshot of these individuals at a certain age, it would be impossible to distinguish between cognitive fluctuations and decline. If we would do so at age 70 (indicated by the black dot), we would conclude that the blue and red individual have similar cognitive functioning, even though their development is very different.\nThus to determine whether presidential candidates have a bad night or whether they experience actual cognitive decline, we need information on cognitive functioning over a longer period of time. Of course, age matters in the context of cognitive functioning, but age by itself is no guarantee for substantial decline. So, try to see the bigger picture and don’t get distracted by one shaky debate.\nJessica Schaaf, researcher in cognitive fluctuations\n\n\n\n",
    "preview": "posts/2024-10-31-Elections/trump_vs_harris.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-10-04-lab-retreat/",
    "title": "Lab writing retreat",
    "description": {},
    "author": [
      {
        "name": "Sophie Hofman & Ben Kretzler",
        "url": {}
      }
    ],
    "date": "2024-10-04",
    "categories": [],
    "contents": "\nLab writing retreat\nLast month, we went on our very first multi-day writing retreat. For three days and two nights, nearly the entire lab gathered in (a not so sunny) Voorthuizen (a village near the Veluwe), travelling together from various starting points all across the Netherlands.\n\n\n\nTo start off our lab retreat, Rogier presented an overview of the past, present and future of the lab, followed by a group discussion on the current state of our lab. We talked about what already functioned well, how we could work even more efficiently, and discussed possible improvements for our lab experience. Some of these suggestions are already implemented by now (one month later): for example, we implemented regular intervision sessions where we talk about our work struggles together, and reinvigorated our ‘Eat The Frog’ session where we commit 1 hour to (only) admin tasks.\nYet, as we went on a writing retreat, we also reserved a significant portion of our time for everybody to work on their most pressing coding, paper, or thesis projects: a major goal of the retreat was to complete (or make significant progress) in our writing tasks. To facilitate concentrated work, we scheduled several long writing sessions across the three days, where we all sat together and made progress in our individual duties. The big tables in the house served as a perfect big homemade lab office, and concentration lapses were efficiently tackled by the large supply of snacks available.\nBeyond the writing sessions, we devoted an entire morning to a collaborative writing project on the versatility of structural equation models for conducting various parametric tests. We split into several groups, each working on different sections (e.g., introduction, simulation), and managed to achieve an impressive amount of work in just three hours! Besides, we all became more acquainted with our lab’s favourite statistical tool (R).\n\n\n\nHowever, the retreat was not solely about work but also about building community. We shared breakfast in the mornings and cooked and enjoyed lunch and dinner together. When we weren’t working, in the evenings or during the breaks, we filled our time with fun activities. A thrilling pub quiz saw Nebbe, Jordy and Aran take first place, and (paddle) teacher Jessica taught self-proclaimed Roger Federers some new paddle tricks.\n\n\n\n\n\n\nGood weather, unfortunately, did not travel with us to Voorthuizen, so walks through the Veluwe were cut short due to some (heavy) summer rain. When the sun did decide to grant us its presence, we could all relax in the garden after a Tuesday full of work, with the help of Luisa’s yoga class. Here our lab members demonstrated that their competence is not necessarily limited to cognitive flexibility.\n\n\n\nThe three days we spent in Voorthuizen were an awesome experience for the whole lab. We worked, wrote and walked together, cooked, connected and collaborated during shared projects, and discussed and discovered new ideas for future work. All in all, it is definitely something worth repeating!\n\n\n\n",
    "preview": "posts/2024-10-04-lab-retreat/distill-preview.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-07-12-GUIS-Rogier/",
    "title": "Growing Up In Science - Rogier Kievit",
    "description": {},
    "author": [
      {
        "name": "Rogier Kievit",
        "url": {}
      }
    ],
    "date": "2024-07-12",
    "categories": [],
    "contents": "\nGrowing Up In Science\n\n\n\nA while back, I was asked to be a guest at the ‘Growing Up In Science’ conversation series. This series of events, initiated by Wei Ji Ma and Cristina Alberini in 2014, encourages scientists to talk about their personal journey, development, insecurities and struggles, and how they juggle the demands of academia with their personal journey. Below, I have described my (Rogier Kievit’s) story of Growing Up In Science.\n\n\n\nA wandering mind\nI was born in Delft, the Netherlands in 1982. I was always interested in science, or rather, the natural world. I was (and am) happiest staring into ponds and streams searching for fish, or reading about dinosaurs, snakes and volcanoes. Once, my mother kindly accompanied me to a museum with a rock I had found in the mountains on holiday. In it, I was certain, was a fossilized rodent of some kind. The very kind professional at the local museum explained it was simply a pattern in a very nice rock.\nMy childhood was happy and stable and had plenty of academic support. My mother was a lab technician in a biology lab, and later a policy officer at the Netherlands Institute for Advanced Studies, and my father was a surgeon as well as a professor of Medical Decision making. However, my parents made a concerted and successful effort to not translate their own achievements into overbearing pressure on me or my two brothers. In fact, it was my wife who, several years into my PhD, pointed out to me that my father had published a paper in Science, which he had neglected to mention. Similarly, it was my PhD supervisor who pointed out to me that it was quite unique that I did not experience any pressure to perform or achieve, which I am quite thankful for. I have plenty of inner restlessness driving myself forward for it to not be amplified externally.\nOur secondary school encouraged attending University ‘Open Days’ to explore possible degrees, an opportunity I grabbed with both hands. The magnetism of Amsterdam was irresistible, and the open day included a mesmerizing lecture on memory, where the late Christiaan Hamakers demonstrated how chunking could easily triple our memory capacity. Between that visit and devouring the book ‘The Minds’ I’, a collection of short stories on minds and brains edited by Douglas Hofstadter and Daniel Dennett, I knew for sure: I wanted to study psychology, philosophy and neuroscience to better understand the mind and brain. I vividly remember one of my first lectures in philosophy – it was a deeply challenging lecture on logic, from seven to ten in the evening, in the heart of Amsterdam. Afterwards, we walked over the lantern-lit canals to the local pub to continue our discussions on the nature of life, the universe and everything. Studying was everything I hoped it would be.\nMy diverse interests, ranging from psychology, neuroscience and statistics to philosophy (of mind) and data science offered me a lot of academic liberty during my degree and research career. I happened to wander into cognitive neuroscience, but I would have been just as happy with a career in biology, physics, palaeontology or any of the other exciting topics – I regularly experience academic ‘fear of missing out’ when I read about people working at CERN, measuring animal behaviour in the jungle or modelling shark migrations. I started out my career as a PhD student being the ‘brain-person’ in a statistics department and have continued as the ‘statistics person in a brain department’. My diverse interests have meant that I feel (mostly) at home in a lot of places and settings - But also that I never fully belong in one place. I’ve never had a must-attend conference, or a must-read journal. I’ve often thought, especially during my PhD, that it must be easier simply pick a more specific subdiscipline, really dig deep, and be part a single community. At the same time, I know that ultimately that isn’t who I am, and that a key reason I am still excited about the substance of my research is that I’ve been allowed to roam far and wide.\nOf course, even when things go relatively well in academia you’ll have to deal with rejection regularly. I vividly remember that my first paper, that I had worked on for almost 2 years, was out for review while I was on holiday. I made the newbie mistake of checking my work email from our hiking holiday in Scotland, to find not just a rejection, but one that included the phrase ‘this might have been sensible and innovative a decade or so ago.’ Another challenge with my interdisciplinary work and interests is an exacerbation of impostor’s syndrome. Wandering within and between disciplines makes you even more acutely aware that no matter what topic or skill you pick, other people will be more skilled or knowledgeable. I remember arriving in Cambridge and being astounded that someone with considerably greater mathematical skills than my own had simply reimplemented a popular quantitative package in MATLAB. The skills I feel more insecure about tend to feel like magic when I see others excel at them. Over time I learned to manage these feelings and have found some degree of inner peace with my insecurities, knowing that my constellation of weaknesses and strengths is good enough to do my job properly.\nThe two (three, four…) body problem\nMy wife (Anne-Laura van Harmelen, professor of Brain, Safety and Resilience at Leiden University) and I met during our master’s degree, spending our internships at Harvard. Experiencing an entire academic career together, from student to full professor, is very inspiring and rewarding. It also gives me rather acute insight into the many smaller and larger effects of systemic sexism and other forms of bias in society at large and academia more specifically. My academic authority is much more readily assumed than hers, no matter the setting or topic. I’ve always been acutely aware of the many privileges I’ve had – my father was a professor, my mother worked as an academic editor, and I’m a white, cis, hetero male raised bilingually in a country that funds higher education properly. I have tried to ‘spend’ some of this academic privilege on trying to improve these disparities and work towards causes I value, from equality and diversity to open science and climate action. In addition to their intrinsic value, I think spending time and mental space on bigger problems is valuable, as it often gives more immediate and tangible rewards compared to the delayed and ethereal impact of more purely academic work.\nAt the end of our PhD, we visited Cambridge (UK) together, ultimately translating into a postdoc opportunity for both of us to work at the MRC Cognition and Brain Sciences Unit. We hoped to move to Cambridge, have our child there, and for me to finish my PhD in the first two months before the postdoc started and the baby arrived. However, our son had different plans in store….\n(Less than) one in a million\nFive days before we were supposed to emigrate to the UK to our new life, our son was born. Nine weeks premature, so small, and so fragile. Our belongings moved to the UK without us. Living in our empty apartment in Amsterdam was an apt metaphor of our experience of becoming parents. Our son confined to a beeping, buzzing incubator. After eight weeks of ups and downs in the hospital, we were finally allowed to leave and, within days, move across the channel with our son. By now he was a huge baby to us, but still a tiny baby to everyone else.\nAfter settling into our new home, country and job, I could choose between two options. Only focusing on finishing my, already delayed, PhD thesis, would mean that the large project (Cam-CAN) on which I was a postdoc would inevitably barge ahead without me. But if I only focused on my new postdoc, it would become increasingly hard, if not impossible, to finish my thesis. So, for several months I did both, in a schedule I cannot enthusiastically endorse. From 9:00-5:00 I was a regular postdoc. After that, we picked up our son from daycare, and we did all the parenting things together, dinner, bath, bedtime. At around 20:00 or 20:30 I cycled back to work, to work on my PhD thesis until about midnight, fuelled by Twirl bars from the vending machines and the enjoyment of scaring the security guard on his rounds through the building. Apart from that period, we have mostly resisted the toxic ‘work all the time’ ethic. Little did we know that some of the most challenging times were still ahead.\nOn the 31st of August 2013, I finally finished my PhD thesis, sent it over to my PhD supervisor, and celebrated with an ice-cold beer and an early bed. Around midnight, we woke up because of some odd noises coming from our son’s bedroom. I rushed over, and found him blue in the face, almost unresponsive. We called an ambulance, who arrived 8 minutes later, and rushed to the hospital where his seizures and breathing problems subsided.\nOver the next few weeks, we slowly descended the ladder of diagnostic prevalence. First diagnosis: febrile seizures associated with sudden fever spikes. 1 in 20. But the seizures kept coming back, without any fever. Next diagnosis: infantile spasms. 1 in 2000. Then, tuberous sclerosis. 1 in 15000. None of the symptoms quite fit, and none of the treatments quite worked. Finally, after all other avenues had been exhausted, our doctor conducted a full genetic screen. The diagnosis came back: ‘Ring 14 chromosome disorder’. Only 76 reported cases in the published literature. Our son was 1 in… 80 million? Our diagnostic rollercoaster came to an end, only to be replaced by a less metaphorical one. In total, we had to take more than 20 ambulance trips due to severe epilepsy – We even started to be recognized by ambulance crews when walking around Cambridge, who waved kindly at our son Flynn. Ambulance crew are lovely people, but you generally don’t want them to recognize you. It was a time when work and home life collided jarringly. Before, I might have glossed over sections in neuroscientific papers referring to participants with ‘refractory epilepsy’. But now I had a much more visceral appreciation about what that simple phrase means for them, their families and surroundings.\nIt was also a time where the intrinsic value of being a scientist was a powerful way to keep us going. It allowed me to wrench some degree of control back from our circumstances - Yes, I was a father, but I was also other things. Although neither of our supervisors in any way forced us to work (quite the opposite), being able to combine long days in the hospital with work was an incredibly valuable activity. And no matter what the universe threw at our family, this gave us some sense of autonomy, control and agency. Both Anne-Laura and I even ended up submitting fellowship applications from the A&E department, to not let our hard work go to waste. We’ve since kept some of this stubbornness, refusing to let our son’s challenges dictate what we could and couldn’t achieve.\nAlthough I have been very lucky in my academic career, I also experienced my share of disappointments. One particularly impactful one was being shortlisted to become a postdoctoral fellow at St. John’s College in Cambridge. This historical place seemed like magic to me, and the idea that I could be a small ‘part of it’ was extremely exciting. I was very nervous for the interview. During the interview I was extremely focused on not making any ‘mistakes’, and was therefore (I suspect) an extremely boring candidate. Unsurprisingly, I didn’t get the fellowship. A later round of a similar interview with a different college, I was far less nervous – I was relaxed, myself, and willing to share my actual ideas and views. It went much better. Although the disappointment of the first interview (in my own performance more than not getting the position) was tough, it was a valuable lesson in that playing it safe is rarely the better option. I committed to more fully being myself for any future career opportunities.\nIn 2015, a stroke of brilliance by our son’s clinical neurologist led to the introduction of two new medications to help with his epilepsy and immune problems. Suddenly, he was 100% seizure free, a treatment so successful our son is now a published case study. At the same time, the uncertainty of my professional future hung above us like a cloud. Our daughter was about to be born, and I only had a few months left on my postdoc contract, with no clear options. Moving would be very hard, and one possible job opening was less science and more organisational, not a move I was hoping to have to make. Should we go back to the Netherlands, to at least have more of a social support structure with the children? Or ‘stick it out’ and hope something would come on our path?\nLuckily, I was shortlisted for a Wellcome Trust fellowship, and my interview was scheduled 10 days after our daughter was born. The fact that both she and my wife were healthy gave me a healthy dose of perspective. The otherwise daunting, U-shaped collective of 15 stern professors were suddenly quite a bit less daunting than they might otherwise have been, and I was lucky to be awarded the fellowship. Within the space of 2 months, we were now a family of four, I suddenly had at least some semblance of job security, and our regular ambulance trips were a thing of the past.\nOur son’s rocky road has taught us a lot of valuable life lessons. During our PhD’s, we regularly pushed up against, and over, our own limits. Although our time working in the US and seeing firsthand the excesses at Harvard and MIT gave us a healthy scepticism of the culture of always being in the lab just to be seen, we were not entirely immune to this pressure. One benefit, if you can call it that, of spending as much time in various wards of hospitals is to instil a good sense of perspective. We decided that we would, at least as a rule, not work on weekends, and don’t work excessively in the evenings, and try to model that behaviour to our labs. Rather than harm our productivity, I think it has made us more balanced and efficient. Academia can be very demanding, but the notion that it is only possible to be successful if you spend 70-80 hours in the lab is simply nonsense.\n\n\n\nA home away from home?\nWe were quite happy living in the UK, and especially Cambridge. I like the feeling of living abroad. It made me behave more as a tourist: Scouring google maps for sightseeing spots, or blobs of undifferentiated green, to go and explore. The period of stability after my wife and I established our own groups was somewhat short-lived. Like many others, we never expected the Brexit vote to go the way it did – but suddenly we woke up in our neighbourhood, and every single house around us had an English flag outside their house. This vague sense of unease was compounded by an election that explicitly suggested children from the EU were the reason schools were too full. Somewhat by chance (or perhaps not), we were both invited to apply for professorships in Leiden and the Donders institute. My wife had very fond memories of her time in Leiden as a PhD student, and for me the Donders was exactly the international, interdisciplinary hub I feel most at home in. We both got the jobs. Next step: trying to move countries, find schools, and even buying a house over videochat during the first pandemic lockdowns.\nBack home\n\n\n\nAccepting our new posts gave a healthy renewed dose of impostor’s syndrome. The academic career goal (and stability) of a position of full professor (hoogleraar) had been achieved – but in practice, it didn’t seem to mean very much. I was still stuck behind the kitchen table, trying to figure out how to get started in a new post through a maze of intranet pages and 3 factor logins. The main change in my role seemed to be my email signature. But, we slowly settled in, and I now have a wonderful, international lab who show me every day how to do things differently, and often better, than I would. Although life is a bit more stable now, children with special needs are often able to throw a curveball. Right now, I’m writing this section from beside my son’s hospital bed, where we have been for 8 days and counting. Writing, whilst keeping an eye on the saturation monitor which has been our window into a(nother) bout of pneumonia. Our son’s ups and downs still happen, and they are still not easy, but we have gotten better at dealing with them, and to fit them in in our larger, more balanced picture of our identities.\nA career in academia isn’t easy, but it can be immensely rewarding. The most important thing is to stay curious – about the work you do, about yourself and the people around you, and about the world around us. The best way to maintain that childlike sense of wonder and curiosity is to find ways to change your perspective – That can mean traveling, diving into new topics or collaborations, or reading well beyond your own field. Moreover, you need a healthy balance between your role and life as a scientist, and the even more important ‘everything else’ – Including the arrival of a very welcome daughter to our family this summer. I love the idea of playing a very small role in this human endeavour, stretching across millennia, of unravelling nature’s mysteries. Having laid a brick, or half a brick, in this edifice of knowledge and wonder we have built, I marvel on many days that I’m able to make a job of figuring things out. I wouldn’t want it any other way.\n\n\n\n\n\n\n",
    "preview": "posts/2024-07-12-GUIS-Rogier/distill-preview.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-06-10-Modelling-Practices/",
    "title": "The good, the bad and the improved practices for statistical modelling - A crowdsourcing project",
    "description": {},
    "author": [
      {
        "name": "Ilse Coolen",
        "url": {}
      }
    ],
    "date": "2024-06-10",
    "categories": [],
    "contents": "\r\nPractices in statistical modelling\r\nKicking off with the famous George Box words that “all models are bad, but some can be useful”; but how to avoid pitfalls and ensure that a model does indeed fall within the useful category?\r\nStatistical modelling is a powerful tool to answer a wide range of research questions and provides valuable insights in understanding complex systems or phenomena. However, in fields such as psychology, most researchers are not statisticians or do not have an expert background in statistical modelling. Whether you are stepping into the realm of modelling for the first time or have been navigating it for a while, chances are that you are self-taught out of curiosity or necessity for your research. The lack of widespread knowledge about this statistical technique results in some common pitfalls that can reduce the quality of the models developed.\r\nTherefore, I organised a lab meeting with the Lifespan Cognitive Dynamics Lab, which has a strong focus on statistical approaches such as SEM, linear mixed modelling, mixture modelling and related approaches, with the goal to gather some bad and good practices in modelling. The first aim of this post is to raise awareness and give you the handles to avoid bad practices in statistical modelling and turn them into good ones. The second aim is to invite anyone with additional bad or good practices in statistical modelling, to add their experience to the document.\r\nThough this list will not be exhaustive, I hope that other researchers will add their knowledge and I hope it will aid fellow researchers in navigating the complexities of statistical modelling with greater confidence by becoming aware of potential pitfalls.\r\nProcedure and insights of the lab meeting\r\nI asked each lab member to prepare at least one bad and one good practice that they had previously encountered or experienced in modelling, which we then categorised in one of 3 categories during the meeting: (A) data handling and pre-processing, (B) model development and selections, and (C) documentation and interpretation. The categories weren’t communicated beforehand to allow out-of-the-box thinking. Each practice was discussed and nuances were added where needed. For each bad practice we tried to come up with a way around it or turn them into a good practice. Figure 1 shows the final board with all the suggested practices that were discussed for an overview. Each of the practices are explained in more details in the original document:https://osf.io/preprints/psyarxiv/tcxne.\r\nFigure 1.\r\nOverview of practices discussed within the LCD lab meeting\r\n\r\n\r\n\r\nA crowdsourcing project\r\nDo you believe there are some crucial practices missing? I invite you to read the guidelines of contributing to this crowdsourcing document and make your suggestions on the editable google doc.\r\nWe welcome any contributions in the form of additional bad/good/improved practices or modifications/nuances to an existing practice.\r\nI will periodically verify the suggestions made and upload a new ReadOnly/preprinted version including your contributions if these are accepted. The new version of the preprint will then be shared on social media (Twitter/BlueSky).\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-06-10-Modelling-Practices/distill-preview.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-03-18-Music-Education/",
    "title": "Sound Foundations: Children and Music Education",
    "description": "Why everyone should get music education",
    "author": [
      {
        "name": "Liza Rozman",
        "url": {}
      }
    ],
    "date": "2024-03-18",
    "categories": [],
    "contents": "\r\n{=html}\r\n\r\n\r\n\r\nWould you believe me if I told you that there is a way to improve our memory and cognitive function while having fun? Well, maybe not fun in a traditional sense, but it’s definitely better than sticking to a diet or taking medication. I’m talking about music education. And while the aspect of going to yet another educational institution might not sound that appealing, just wait for me to make my case and decide at the end. Although, let me first say that I am biased and have a few years of music education behind me, so this is based on personal experience (and scientific research).\r\nScientists have found that a person benefits the most if they start learning an instrument (from a professional) from the age of seven and continued to do so, for at least two years. Even only two years of music education have shown some differences in brain structures and their function compared to non-musicians (Holochwost et al., 2017). When musicians were put into a scanner and asked to do simple memory tasks and math problems, the respective brain areas light up relative to the task. But when they were asked to listen to music, all those areas that were previously lighting up individually were now firing together. This is because music stimulates the motor, visual and auditory areas all at once – like a full body workout, but for the brain (Hodges, 2000). They also found that musicians had higher levels of executive functions, highly developed memory systems, and general cognitive capacity (Holochwost et al., 2017). While I cannot attest to better cognitive functioning and capacity, I can tell you that I have had to learn hundreds of classical pieces by heart and as a piano player, not only can I read a completely different language – musical notes, I can also read two lines at the same time (something that is only handy in a musical setting, and not so much when reading books). Additionally, scientists found that the area which connects both sides of the brain is bigger in musicians, and this allows for the information to travel a lot faster and why musicians can play those notes so quickly (Stewart, 2008).\r\nWhile one might not be that impressed by the quick fingers, music education has also been helpful in improving learning disabilities. For example, a study in France showed that 6-week musical training improved auditory awareness, phonological awareness, and reading ability in dyslexic children ages 8-12 (Habib, Lardy, Desiles, & Besson, 2016). Additionally, people with Attention Deficit/Hyperactivity Disorder (ADHD), also tend to respond positively to music. They can sustain their attention longer, and work on monotonous tasks without getting bored for longer (Martin-Moratinos, Bella-Fernández, & Blasco-Fontecilla, 2023). Although, I think that is true for everyone.\r\nIf by now you are not convinced why children should go to music school (it’s never too late for adults either), let’s quickly talk about IQ and the future of humankind. Some studies have shown that music education before the age of seven, can result in a higher IQ by about 7.5 points (Schellenberg, 2004). This might not seem like much but imagine what future classrooms and education would look like if all children were given a few years of music education and the average IQ was higher with each generation and so were literacy and numeracy levels. All because the parents endured a couple of years of screeching instruments.\r\nAnd while they would spend their free time doing additional homework and going to yet another school in the afternoon, they would also learn how to manage their time better, make friends that are not just in their school districts, and learn how to be more confident and have a better stage presence so all those recitals don’t go to waste either.\r\nTo conclude, music education is not for the talented. It is for people to develop into talented individuals that are fully equipped for the real world and can spread and enjoy one of the oldest forms of communication – music.\r\nReferences:\r\nHabib, M., Lardy, C., Desiles, T., & Besson, M. (2016). Music and dyslexia: a new musical training method to improve reading and related disorders. Frontiers in psychology, 7, 141238.\r\nHodges, D. A. (2000). Implication of Music and Brain Research: This introductoray article offers an overview of neuromusical research and articulate some basic premises derived from this research. Music Educators Journal, 87(2), 17-22.\r\nHolochwost, S. J., Propper, C. B., Wolf, D. P., Willoughby, M. T., Fisher, K. R., Kolacz, J., . . . Jaffee, S. R. (2017). Music education, academic achievement, and executive functions. Psychology of Aesthetics, Creativity, and the Arts, 11(2), 147.\r\nMartin-Moratinos, M., Bella-Fernández, M., & Blasco-Fontecilla, H. (2023). Effects of music on attention-deficit/hyperactivity disorder (ADHD) and potential application in serious video games: systematic review. Journal of medical Internet research, 25, e37742.\r\nSchellenberg, E. G. (2004). Music lessons enhance IQ. Psychological science, 15(8), 511-514.\r\nStewart, L. (2008). Do musicians have different brains? Clinical medicine, 8(3), 304.\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-03-18-Music-Education/musiceducation.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-03-08-Arendt/",
    "title": "Why should we study individual differences and variability? Philosophy edition",
    "description": "Not only Fiske and Cattell, but also Arendt and Foucault knew that it takes more than just means and standard deviations.",
    "author": [
      {
        "name": "Ben Kretzler",
        "url": {}
      }
    ],
    "date": "2024-03-08",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nWhen scientists who study behavioral or cognitive variability (or, more widespread, individual differences) are asked about the value of their research, it seems as if they often quote fellow researchers who pointed to the weaknesses of solely studying global means and standard deviations—and indeed, there is stuff out there: for example, and perhaps most prominently, Raymond Cattell stated already during the 1960s that ignoring variability in performances is a “moral failure” because high-impact decisions are frequently made based on results that stem from one particular moment in time (e.g., university admission based on a test score). In this blog post, we would like to go one step further and document criticism about aggregate statistics from about the same time but outside psychological science, and see whether such statements from psychologists and non-psychologists relate to one another.\r\nHannah Arendt: ‘The Justification of Statistics is That Deeds and Events Are Rare Occurrences’\r\nLet us begin with philosopher and political theorist Hannah Arendt. In 1958, she published The Human Condition, where she famously differentiated between vita activa (i.e., engagement with the external world, such as labor and political engagement) and vita contemplativa (i.e., inner reflection and thought). However, when Arendt writes about the modern state and her claim that this institution enforces conformity, she also formulates a general critique of statistics and, to her, the most representative social science, which is economics:\r\nEconomics […] could achieve a scientific character only when men had become social beings and unanimously followed certain patterns of behavior, so that those who did not keep the rules could be considered to be asocial or abnormal. The laws of statistics are valid only where large numbers or long periods are involved, and acts or events can statistically appear only as deviations or fluctuations. The justification of statistics is that deeds and events are rare occurrences in everyday life and history (Arendt, 1958, p. 41–42).\r\nThis criticism is remarkably anticipative of modern criticism of classical test theory, particularly the assumption that, by randomly drawing individuals from a presumably homogenous population and aggregating these measurements, ‘true scores’ for the entire population can be derived (cf. Molenaar, 2008). Furthermore, the notion that such scores cannot mirror the variability that comes with ‘acts and events’ (or ‘deviations and fluctuations’) shares some conceptual ground with Cartier’s ‘moral failure’ argument: even when an aggregate measure is valid for the majority of cases, one should expect that it is not predictive for a significant number of scenarios, and, therefore, shy away from making inferences based on one score alone. Thus, even though Arendt was not interested in psychological measurement theory per se, she could, in a book that focused on the social and political life in Western societies, name weaknesses of social science research that would only years later become part of a broader scientific debate.\r\nAfter these statements about a neglect of minority cases through statistical practices, Arendt goes on by linking this neglect to ‘mainstreaming’ tendencies: When only aggregate scores are considered by policymakers, the resulting policies will be ‘overfitted’ regarding the wishes of the median individual but perhaps not adequately represent those with differing needs. In turn, that incentivizes people to behave like the ‘median.’\r\nHowever, since the laws of statistics are perfectly valid where we deal with large numbers, it is obvious that every increase in population means an increased validity and a marked decrease of “deviation.” […] The unfortunate truth about behaviorism and the validity of its “laws” is that the more people there are, the more likely they are to behave and the less likely to tolerate non-behavior. Statistically, this will be shown in the leveling out of fluctuation (Arendt 1958, p. 43).\r\nNote that this reasoning is an interesting preview of modern performativity literature that claims that, due to the questionable assumptions they are working with, the social sciences (and here, again, particularly economics) are complicit in creating the world that they initially wanted to describe (Callon, 1998): indeed, the idea that there are ‘true scores’ that can ground general policies may be a good example for such questionable assumptions.\r\nMichel Foucault: ‘Individuals Will in Turn Behave as They Should’\r\nNow, let us take a brief look at the lectures and writings of Michel Foucault, one of Arendt’s contemporary philosophers. At the end of the 1970s, he established the claim that statistics is the key means by which the political domain influences, if not dominates, social life (the concept of ‘pastoralization’):\r\n[The art of government] was also connected to a set of analyses and forms of knowledge […] which were […] essentially to do with knowledge of the state, in all its different elements, dimensions, and factors of power, questions which were termed precisely ‘statistics,’ meaning the science of the state (Foucault, 1979, p. 231).\r\nHence, according to Foucault, modern states employ statistical analysis to acquire knowledge about their citizens, using data from an increasingly large and powerful bureaucracy. From here, Foucault arrives at a similar position as Arendt when he goes on by writing that this knowledge will determine the state’s actions and, therewith, the citizens’ behavior:\r\nWhen a state is well run [i.e., knows its citizens] the head of the family will know how to look after his family […] which means individuals will in turn behave as they should (Foucault 1978/1991, p. 92).\r\nNice (or Not), But What Does It Have to Do With Psychology?\r\nIn summary, both Arendt and Foucault posit that the modern state induces ‘mainstream’ uniform behavior among its citizens and that statistics is an essential means to enable it in doing so. Moreover, Arendt goes one step further in claiming that the neglect of individual differences and variability initially causes a similar neglect in policies that, only then, leads to uniformity.\r\nThe nature of these arguments comes close to recent research works that criticize that psychology tends to develop one-size-fits-it-all solutions, for instance, in therapy design (e.g., Cloître, 2015), which may be caused by only looking at aggregate trends and not the individuals itself (for alternative concepts, cf. Cohen, 2021; Olthof et al., 2023). Hence, although they are writing about the use of statistics primarily in economic research, Foucault and particularly Arendt are pointing out problems that apply to quantitative research in general. That psychological science may only be able to address their decade-old criticism these days points to a long-unused potential of Arendt’s and Foucault’s texts in identifying problems in research practice.\r\nConclusion\r\nTaken together, this blog post documents a tempting correlation (but not causation!) between criticism about aggregate statistics from inside psychological research, such as Cattell’s moral-failure quote, and more general criticism about research practices in the social sciences from ‘outsiders’ such as Arendt and Foucault. Although they are (i) not coming from the field of psychology or statistics, (ii) not primarily writing about research methods but about modern politics and society, and (iii) generally afraid of the power of data collection and statistical analysis in predicting and controlling the behavior of citizens within a state, Arendt and Foucault can still identify weaknesses of statistical practice that are still valid these days. Indeed, the sometimes very close resemblance between these statements and the goals of today’s research agendas on individual differences and human variability suggests that aligning the development within such research fields with influences from other disciplines and larger societal debates may be helpful to understand why psychological research developed the way that it did. Finally, when looking for suggestions on how to improve contemporary research practices, it could be equally beneficial to not only search within the academic literature but also to think about where we currently fail to detect, cannot adequately represent, or neglect societal problems with our studies’ methodologies, results, and conclusions.\r\nReferences\r\nArendt, H. (1958). The human condition (2nd ed.). Chicago University Press\r\nCallon, M. (1998). Introduction: The embeddedness of economic markets in economics. The Sociological Review, 46, 1–58.\r\nCloître, M. (2015). The “one size fits all” approach to trauma treatment: should we be satisfied? European Journal of Psychotraumatology, 6(1). https://doi.org/10.3402/ejpt.v6.27344\r\nCohen, Z. D., Delgadillo, J., & DeRubeis, R. J. (2021). Personalized treatment approaches. In M. Barkham, W. Lutz, & L. G. Castonguay (Eds.), Bergin and Garfield’s handbook of psychotherapy and behavior change: 50th anniversary edition (7th ed., pp. 673–703). John Wiley & Sons.\r\nFoucault, M. (1978/1991). Governmentality. In G. Burchell, C. Gordon & P. Miller (Eds.), The Foucault effect: Studies in governmentality with two lectures by and an interview with Michel Foucault (pp. 87–104). Chicago University Press\r\nFoucault, M. (1979). Discipline and punish: The birth of the prison. Peregrine.\r\nMolenaar, P. C. M. (2008). Consequences of the ergodic theorems for classical test theory, factor analysis, and the analysis of developmental processes. In S. Hofer & D. Alwin (Eds.), Handbook of cognitive aging: Interdisciplinary perspectives (pp. 90–104). SAGE Publications. https://doi.org/10.4135/9781412976589\r\nOlthof, M., Hasselman, F., Oude Maatman, F., Bosman, A. M. T., & Lichtwarck-Aschoff, A. (2023). Complexity theory of psychopathology. Journal of Psychopathology and Clinical Science, 132(3), 314–323. https://doi.org/10.1037/abn0000740\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-03-08-Arendt/ArendtImage.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-02-03-Confidence/",
    "title": "Confidence, and how to fake it!",
    "description": "Becoming more self confident in academics",
    "author": [
      {
        "name": "Nebbe Al-Moula",
        "url": {}
      }
    ],
    "date": "2024-02-08",
    "categories": [],
    "contents": "\n\n\n\nIn academia, and life in general, having a little bit of confidence can open many doors. Opportunities are often given to those who believe in themselves and put themselves out there. So confidence is useful, great! What do you do when you are not a naturally confident person? In this blog post we will discuss a few tricks to make yourself appear more confident.\nThe three second rule\nWhen doing public speaking, presentations, or when putting yourself out there in general, confidence is of utmost importance. Coming across as confident will make the listeners trust in your words and believe that whatever you have to say is worthwhile. However, many people find these things nerve wrecking. This is why a good friend of mine taught me “the three second rule”. The three second rule basically says that it only takes three seconds of courage to do something that scares you. For example, you only need three seconds of courage to get up and start your presentation, once you are going you probably wont just give up and sit back down. This rule can be used in any situation you are nervous about. These three seconds of courage won’t necessarily make you any less scared or nervous, but it will help you get started. The most difficult part about public speaking or presentations is the moments leading up to it, during this time you can drive yourself crazy with self-doubt and over thinking. The three second rule is meant to override those thoughts momentarily so you can get a good start.\nDelusions of grandeur\nNow that you’ve mustered up your three seconds of courage and you started your talk, how do you exude this confidence physically. To come across as confident your posture, cadence, and body language are crucial. If you fidget, speak to quickly or too softly, stand hunched over, or constantly look down, you will seem nervous. The solution to this is delusion! Imagine yourself as an important TED talk speaker, or a popular celebrity. Ask yourself how that person would carry themselves during a presentation, and imitate that. You can be performative about it. It’s not a potentially embarrassing presentation, it’s a role you are playing and you are an amazing actor. To your listeners every talk you give is equally important, every presentation is your magnum opus and you should treat it as such. Often times we think we are speaking very loudly or that our gestures are too big and crazy, what I’ve learned is that in reality we don’t look as crazy as we think we do. We tend to automatically tone down our movements and voice when we get nervous, this means that to get the desired effect you have to over-exaggerate everything. So even if it feels stupid, use those extravagant hand gestures and speak like you are delivering a monologue.\nIn conclusion, everyone struggles with self-confidence sometimes. However, with a little bit of courage and a healthy amount of delusion confidence and be faked and eventually built. It is important that we remember that no one is confident all of the time about everything, but everyone will notice the effort you put in to build up your confidence.\n\n\n\n",
    "preview": "posts/2024-02-03-Confidence/ConfidenceImage.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-01-02-scicom/",
    "title": "The icing on the cake",
    "description": "Why science communication should be part of everyone's science",
    "author": [
      {
        "name": "Jessica Schaaf",
        "url": {}
      }
    ],
    "date": "2024-01-02",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nThis year I came up with a New Year’s resolution that I can actually keep: more science communication. So let’s get off to a good start with some science communication… on… science communication!\r\nIn my opinion, science communication entails all communication that aims to convey scientific knowledge, for example, to spark interest or to create awareness or enjoyment. Although we as scientists are not the only ones who can communicate science, the general public puts a lot of faith in our communication; even more so than in that of, for example, the government or journalists (e.g., KNAW, 2013; Rutjens et al., 2018). Besides, we are trained to critically evaluate each other’s (and our own) work, to connect different sources of information, and to communicate scientific results in a clear comprehensible manner. I therefore see it as a scientist’s duty to convey what they learn to the general public. Because what is scientific knowledge worth if it doesn’t reach the general public?\r\nHuman beings are curious… also about your work, Polly!\r\nHowever, science communication is easier said than done. For instance, how do you decide what to communicate? I know many people who throw in the towel at this point, people like pessimistic Polly. Polly likes science communication, but mainly when other people do it. She assumes “nobody is interested in her findings” because “her research is so fundamental, nobody will understand and nobody cares“. I used to be like Polly but talking to people changed my perspective. Yes… a simple thing like talking to people outside of your scientific bubble helps! It does so because it helps you translate tough science into normal language. And because it helps you realize that everything that you have learned during your studies is new to the general public. Everything that you and your fellow scientists investigate now even more so. People are generally very curious beings, constantly trying to minimize the uncertainty about the world around them. Help them to do so!\r\nTimes are changing… so take the time, Bart!\r\nI also met many people that don’t take the time for science communication, people like busy Bart. Bart isn’t such a fan of science communication because “there are so many other, more important things to do”. And in a way, he is right. Science usually doesn’t incentivize science communication. However, times are changing! Nowadays, almost all universities have active science communication departments (who can help!), grants often require some sort of translational impact or outreach, large grants exclusively for science communication are now available (e.g., from the Dutch Science Agenda) and fun initiatives are popping up (e.g., the “Hoe?Zo! Show” and “Lil’ Scientist”). And even if you don’t care about these things, I would argue communicating your results to a lay public speeds up the writing of your papers: because of character limits on social media platforms, you will notice it helps you think about the main message and how to convey it as clearly as possible.\r\nGet in touch with your creative side and start simple\r\nThere’s no need to be like pessimistic Polly or busy Bart. Science communication can be for everyone. See it as the icing on the cake. Get in touch with your creative self and think about what you like to do. Do you like to find hidden gems in the paper jungle? Once you find them, write about it on social media platforms like X (generally good to reach academics) or LinkedIn (generally good to reach non-academics such as clinicians and teachers). Are you more of a visual person? Create infographics once you have results (I know from experience participants really appreciate this way of keeping them up to date). Of course you can make it as crazy as you want. Writing blog posts on your personal or lab website, organizing workshops, recoding podcasts, and so on. However, start simple! Even sharing a new paper on social media counts as science communication.\r\nSo stop reading and start communicating!\r\nJessica Schaaf\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-01-02-scicom/cherryoncake.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-10-28-Autoregression-And-Cats/",
    "title": "What does your ex have in common with magic cats?",
    "description": "Autoregression in 2 short stories",
    "author": [
      {
        "name": "Michael Aristodemou",
        "url": {}
      }
    ],
    "date": "2023-10-30",
    "categories": [],
    "contents": "\n\n\n\nStory 1: Autoregression and magic cats\nToday, we are launching cats in the air. But don’t worry, these are magic cats. Or so they say. You see some days ago two cats showed up on our doorstep and told us that they could fall from any distance and remain unscathed. These self-purported magic cats bragged about how they learned a simple transformation that allows them to soften their fall. Instead of falling like normal cats, they fall by half of their current distance from the ground every second. So, if a cat is 2 meters above the ground right now, in 1-second they will be 1-meter above the ground and 0.5 meters in 2 seconds. This will continue until the cats are safely on the ground (if they ever make it, but more on this later). Swayed by the charisma of these magic cats we decided to conduct an experiment. We wanted to know if these cats fall differently by launching them 16 meters in the air! As you can imagine, our proposal was not popular with the ethics committee. To gather more evidence that would ensure the safety of the cats we decided to use simulations. In close collaboration with the magic cats, we operationalized their falling process using a short model:\n\\[\nX_t = \\beta*X_{t-1} + \\epsilon_{t}\n\\]\nTo understand this model and ensure the survival of our cats, we decided to create a simple scenario that allows us to solve this equation. This equation states that a cat’s current height (\\(X_t\\)) is determined by their height at the previous measurement interval (\\(X_{t-1}\\); in this case a second ago) multiplied by their ability to slow their fall (in this case by half, \\(\\beta=0.5\\)). The final piece of this equation (\\(\\epsilon_t\\)) captures any external forces that influence the cat’s current height (imagine spontaneously activated wind turbines that could push the cat higher).\nLet’s suppose we do launch a cat 16 meters up in the air. If they can do as they say, then their falling rate over 3 seconds should look like this (grab some pen and paper and follow along):\n\\[\nX_{t} = \\beta*X_{t-1} + \\epsilon_{t}\n\\]\nWe launch the cat in the air. We observe the cat’s height at 4 intervals: \\(X_{t-3}\\) = height at launch 0s, \\(X_{t-2}\\) = at 1s, \\(X_{t-1}\\) = at 2s, \\(X_t\\) = at 3s. Their height at the first measurement (\\(X_{t-3}\\)) is fully determined by the launch height. That’s 16 meters. You can view this as an external force affecting our cat’s vertical distance from the ground (\\(e_{t-3}\\)).\n\\[\nX_{t-3} = \\epsilon_{t-3}\\\\\nX_{t-3} = 16\n\\]\nDuring subsequent measurements the vertical height of the cat will be defined by its height on the previous measurement interval (\\(X_{t-n}\\)) multiplied by the amount that they can slow their fall (\\(\\beta\\)). For simplicity we will assume there are no other external forces acting upon the cat’s height (i.e. (\\(\\epsilon_{t-n<3}=0\\)). So, height at each trial is purely determined by the prior height (\\(X_{t-n}\\)) and slowing ability (\\(\\beta\\)).\n\\[\nX_{t-2}=\\beta\\ast X_{t-3}+\\epsilon_{t-2}\\\\\nX_{t-2}=0.5\\ast16+0\\\\\nX_{t-2}=8\n\\]\nThe cat’s height at the 1-second mark is 8 meters. Next, we halve that to find its height at the 2-second mark.\n\\[\nX_{t-1}=\\beta\\ast X_{t-2}+\\epsilon_{t-1}\\\\\nX_{t-1}=0.5\\ast8+0\\\\\nX_{t-1}=4\\\\\n\\]\nAfter 2-seconds we have 4 meters.\n\\[\nX_t=\\beta\\ast X_{t-1}+\\epsilon_t\\\\\nX_t=0.5\\ast4+0\\\\\nX_t=2\n\\]\nFinally, after 3 seconds the magic cat should be 2 meters above the ground. If you plot the points from the equations you just solved, the red curve in Figure 2 appears. You can see that any forces that cause the magic cats to leave the ground have an exponentially decaying effect on their height. The steepness of this exponential decay is determined by the size of the autoregression coefficient (i.e., the \\(\\beta\\)). If we increase the \\(\\beta\\) to a greater value (e.g. 0.7), the slope of the exponential decay becomes flatter (see the blue line in Figure 1). This means that our cats will linger in the sky for longer, sometimes even when the initial launch is shorter (e.g. 8 vs 16 meters). As for magic cats, they only exist in principle for now. If one day the ethics committee approves of our proposal, these braggadocious felines may need to put their money where their mouth is.\n\n\n\nFigure 2. The falling rate of cats depends on their autoregression. The red solid line depicts a cat with an autoregression coefficient of 0.5. They halve their falling distance every interval (t-n). The blue solid line shows the falling rate of a cat with a higher autoregressive coefficient (0.7). The blue and red dashed lines show the size of the external force that pushes the cats up at launch\nStory 2: Autoregression and why your ex will be mad at you forever\nAt this point you may be thinking, that’s all nice but I came here to learn things about my ex and how they are like a magic cat. Well then consider a couple that’s about to get into a heated argument: John and Luca. You can follow their story using Figure 3. Currently they are both calm and collected. Let’s say their mood is at its average (mood = 0 in Figure 3). John is more sensitive but does not hang on to his feelings for very long (\\(\\beta=0.2\\)). Luca is pretty much the opposite. Luca’s mood is hard to shake but once he gets upset, he is likely going to stay that way (\\(\\beta=0.6\\)). So, this lovely couple is having a relatively boring interaction, when suddenly John notices a notification on Luca’s phone. It’s his sister, or as he likes to call her, bad news. John experiences a sharp spike in his mood (\\(\\epsilon_{t-5} = 6\\)). A second later, he composes himself. He is (almost) back to average now. Luca notices this unperturbed and asks John what’s the matter. John responds with “nothing”. Luca dislikes this response (\\(\\epsilon_{t-4}=2\\)), so he looks away trying to conceal his frustration. This upsets John (\\(\\epsilon_{t-3}=7.76\\)). He grabs Luca by the shoulders and shouts at him. A shocked expression washes over Luca’s face as he pushes John away and locks himself in his room (\\(\\epsilon_{t-2}=5.28\\)).\n\n\n\nFigure 3. This figure shows the emotional trajectory of a couple throughout an argument. The dashed lines show the size of the external force their mood receives by interacting with each other. The solid dots show their observed mood which includes the influence of any external pushes. The hollow dots show their mood when it is only affected by their autoregressive coefficient\nWhat happens next? We leave this to our model. In the absence of any added shocks (\\(\\epsilon_t\\)) both John and Luca would eventually calm down. Luca much later than John. But the catch is that they would never return to zero in the absence of any perturbations. You see these models assume that perturbations affect a system, be it cat or person, for infinity. But the effect becomes infinitesimally small. This is because if you keep dividing a value by the autoregression coefficient, it will never be zero (unless you do this infinite times). Thus, if they remain unaffected by the external world, our magic cats will never land, Luca and John will never be as cool as when they started, and your ex will be a little mad at you—forever.\nConclusion\nI hope that through stories of cats and exes you were able to build some intuition about autoregressive models. These models can be used to gain insight into dynamics that move us beyond the mean and deviations from it. Different combinations of volatility and autoregression can lead to insightfully different risk profiles. So, next time you sit and ponder the world around you, try to look at things through the lens of an autoregressive model.\nAuthor: Michael Aristodemou\n\n\n\n",
    "preview": "posts/2023-10-28-Autoregression-And-Cats/flyingcat.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-08-18-lab-retreat/",
    "title": "A lab retreat day away",
    "description": {},
    "author": [
      {
        "name": "Léa Michel",
        "url": {}
      },
      {
        "name": "Nick Judd",
        "url": {}
      },
      {
        "name": "Ilse Coolen",
        "url": {}
      }
    ],
    "date": "2023-08-18",
    "categories": [],
    "contents": "\nWhen you search for images of researchers on Google, you’re likely to find pictures of groups of people in white lab coats huddled together, deep in conversation about something science-related. But that’s not always the reality for researchers, at least not for us at the Lifespan Cognitive Dynamics lab. Most days, we’re sitting at our desks, clicking away on our computers. However, our recent lab retreat was a refreshing change of pace. For an entire day, we had the opportunity to brainstorm, learn, and collaborate in a way that’s not always possible day-to-day. It was a rare chance to break out of our individual silos and connect with each other in a meaningful way, and we can’t recommend it enough.\nIf you want to plan a lab retreat for your lab, we’re happy to walk you through what we did, what worked well and the impact that this day had on the future of the lab.\n\n\n\nThe first step in organizing a lab retreat is to determine the goals and objectives. What do you hope to achieve from the retreat?\nA great way to start planning a lab retreat is to ask advice from colleagues with experience, as well as the colleagues that you are planning the lab retreat for. Our lab retreat team (Léa, Nick, & Ilse) was lucky to receive advice from Dr. Amy Orben who previously organized a lab away day at Cambridge University. Based on her proposed schedule, we created a Google form to receive input from our colleagues on what they were expecting or what they wanted to achieve with the lab retreat so that we could align everyone’s goals and hopes. We encouraged suggestions and were happy to receive some great ones, such as the presentation roulette.\nWe found that most people wanted to foster a feeling of belonging and community in the lab. To accomplish this we provide several smaller group discussions to made sure that everyone was heard, and had the opportunity to talk in both research-related conversations (i.e., Research Culture and Vision hackathon) and personal discussions and presentations (i.e., ice breaker activity and “what would you do if you were not doing research”).\n\n\n\nOnce you have a clear understanding of the goals and objectives, you can plan the retreat activities accordingly and create an agenda that outlines the activities, sessions and breaks. We felt that it was important to include brainstorming sessions on the lab environment, team building activities and social occasions, to keep it productive and fun. Keep in mind that the schedule needs to be flexible to allow for unforeseen changes or delays. We ended up moving around one activity to accommodate a delay from the start. The full schedule and activities will be detailed below.\nNitty-gritty details\nAfter finalizing the basic structure of the program, the next important step was to ensure that the lab retreat is a hassle-free experience that allows space for fun and bonding.\nFinding a date for 13 people, we selected a date for the retreat two months in advance to allow attendees to plan ahead, especially since some members had to arrange childcare.\nNot too far, not too close\nThe location of the retreat also plays a crucial role in its success. After long discussions, we settled on the Splendor Fabriek, a building that offers workspace for such an event. It could host all of us, was accessible and had all the necessary facilities such as audio-visual equipment.\nFull belly, happy researchers\nFinally, ensure that all basic needs such as food, water, and accommodation are taken care of. We made sure to have coffee, cakes and fruits for the day in our workspace.\nWe also booked a lunch venue near the meeting location and dinner place in the city center, closer to the train station, to accommodate those who live outside of Nijmegen. Additionally, we made sure that the activity planned for the retreat was conveniently located and accessible to all participants. Living in the Netherlands we just made sure that everyone had a bike.\n\n\n\nWhat did we do?\n\n\n\nGet to know the lab\nThe main goal of the retreat was to create a feeling of community, ice breaking is always a go to activity to get to know people even if the members of your lab already know each other quite well. In our case, we had a bunch of new lab members along with some visitors.\nThe ice breaking activity consisted of pairing people and giving them 3min to find the most random fact that they have in common. Among bunny killers and tennis fanatics we found out that two people illegally found themselves on a military base, a really random connection.\nThen Rogier took the floor and presented the lab vision through its past, present and future. With the lab growing and the number of projects increasing it was a good opportunity to look back at the main questions defining the lab and what’s in store for the future.\nOpportunity for everyone to shine\nWith 12 people in the room, we emphasized on time for everyone to speak either through smaller group discussion or through individual presentation but we did not want to focus on work.\nTo know more about our colleagues, we asked them “What would you do if you were not doing research?”. Presentation after presentation we learned about their passion for coffee, national parks and scuba diving. Also, I can now confidently say that this lab’s new purpose should be to build a cat cafe!\nNext, the presentation roulette combines the fun of the surprise and a training experience at the same time. If you’re not familiar with the concept, during a presentation roulette (or presentation karaoke) everyone creates a random set of slides on a topic and one by one people will blindly pick one set and will have to present it as if it was a prepared presentation. Among knitting, building bridges and how to make the perfect tea, we also learned how the Dutch are made of sugar.\n\n\n\nImprove the lab culture\nFinally, we had group discussions on various questions reflecting on our lab and on academia. After each group shared the results of their discussion, we separated the lab in two groups to make them work on the solutions to these issues. The results of these discussions and how we implemented changes in our lab will be available in an upcoming blog post.\nHow can lab meetings be more balanced in terms of who is speaking and who is silent? (~gender imbalance)\nHow to combine family (doesn’t mean only children) and a high demanding job like research?\nWhat being a green researcher means and what could we do to improve your carbon footprint in the lab?\nHow to create collaboration in and outside the lab?\nHow to deal with imposter syndrome?\nWhat do you think scientific outreach should be like?\nWhat is the societal impact of the lab?\nWhat makes for a high-performing team?\n\n\n\nFun fun fun\nThen it was finally time to go have some more fun outside the research world! We headed to Prison Island, an escape game composed of 32 cells with their own game and level of difficulty. In teams of 4, lab members had 1h30 to gain as many points as possible by solving all the cells.\nFinally, we ended the day going to a nice restaurant where we ate delicious food and reminisced about our delightful day.\n\n\n\n\n\n\n",
    "preview": "posts/2023-08-18-lab-retreat/fig1.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-03-23-rainclouds/",
    "title": "From Raincloud Plots 1.0 to Raincloud Plots 2.0 to …",
    "description": {},
    "author": [
      {
        "name": "Jordy van Langen",
        "url": {}
      },
      {
        "name": "Nick Judd",
        "url": {}
      }
    ],
    "date": "2023-03-23",
    "categories": [],
    "contents": "\nWhile the days are still short and dark, this post tries to spark some light by taking you along in our exciting open-science project: Raincloud plots!\nThe beginning - version 1.0\nSomewhere during 2018, a fellow cognitive neuroscientist from Aarhus University, Micah Allen, was experimenting with a new type of data visualization on Twitter (the better Twitter times, Ed.). He was doing so in the R programming language and - crucially - data visualization is one of the many reasons to use R.\n\n\n\nFigure 1: For the historical record, Jon Roiser coined the term ‘raincloud plots’.\n\n\n\nAfter some ‘90 degrees’ rotating and ‘name-coining’, Raincloud Plots were born after which Micah wrote a blogpost on his website (https://neuroconscience.wordpress.com/2018/03/15/introducing-raincloud-plots/).\nShortly after, more people started to get involved such as Davide Poggialli who replicated it in Python, Tom Rhys Marshall recreated these in Matlab, and Kirstie Whitaker who wrapped the various codebases into a Jupyter notebook.\nFrom Tweets to Papers\nThe first instance of the Raincloud plots project took solely place in Twitter DMs which eventually ended up in writing a peer-reviewed paper, or more specifically a ‘software tool article’ that was published in Wellcome Open Research. After a little more than a year, we submitted a revised version of the paper and incorporated the most requested feature, a fully operational ‘raincloudplots’ R-package (https://github.com/jorvlan/raincloudplots).\nUpgrade to version 2.0\nIn 2021, the Dutch research council (NWO) announced the launch of their inaugural Open Science Fund. NWO set up the Open Science Fund as a way to recognise and reward open science practices by supporting projects by researchers who are (or want to be) frontrunners in this movement. Part of the assessment, therefore, included applicants’ open science track record, which counted for 10% of the assessment. Team members Rogier and Jordy applied and raincloudplots were selected. One cool feature of this funding round is that all proposals and review comments were, in principle, made publicly available, showing how Open Science can also be part of the funding cycle! https://www.nwo.nl/en/news/open-science-fund-project-proposals-published-today. There was considerable interest in this first round of the Open Science Fund. A total of 167 admissible applications were assessed, 26 of which were granted.\nSome months later, the project took off and we were given the opportunity to present our project plans during the NWO Open Science webinar series. While talking about the scientific impact of our project, Rogier confessed to the audience some (ambiguous) self-reflection:\n[…] “It is either good or depressing that this will likely be one of the most impactful things I did in my career”[…]\nAfter a good laugh and a fruitful discussion about the history and future of our project and about open science in general, the session ended and we started preparing the next phase of our project.\n\n\n\nFigure 2: NWO Open Science in Practice Webinar Series, Thursday, 14 April 2022\n\n\n\nSlides and recording of the session can be found here:\n* https://www.nwo.nl/sites/nwo/files/media-files/Open%20Science%20Presentation%20Rogier%20Kievit_raincloudplots.pdf\n* https://www.youtube.com/watch?v=Kvcyh_9KSbw&t=1910s)\nA new team member\nIn September 2022, the project team was strengthened with Nicholas Judd, a former visiting PhD student in Rogier’s lab. Now being fully operational, we started organizing online, globally accessible workshops and initiated developing our second raincloudplots R-package, coined ‘ggrain’ (https://github.com/njudd/ggrain). The latter is a ggplot2 extension R-package that allows users to create Raincloud plots - following the ‘Grammar of Graphics’. The package can do a myriad of things, but most importantly it:\nIs highly customizable\nConnects longitudinal observations\nHandles Likert data\nAllows mapping of a covariate.\nFor a complete overview of ggrain such as a 2-by-2 raincloud plot or multiple repeated measures, please see our Vignette.\n\n\n\nFigure 3: An example plot from ‘’ggrain’’.\n\n\n\nThus far, we have organized 3 workshops which received positive reviews and a lot of useful feedback, such as suggesting to include automatic significance testing using ‘geom_signif’. Below is a list of social media outputs from the workshop:\nhttps://twitter.com/SportSciSum/status/1591135705702473728\nhttps://twitter.com/rogierK/status/1573269145617063936\nhttps://twitter.com/ioannik23/status/1591101555998326784\n\n\n\nFigure 4: The fourth and final workshop is scheduled for February 17th, 14:00 CET.\n\n\n\nNWO Open Science day - Utrecht office\nAs part of the awarded grant, we were invited to the NWO Open Science Meetup, to share knowledge, gain inspiration and celebrate the award. After a word of welcome by NWO’s Executive Board, two members of the Open Science Fund review committee shared their experiences during the review process. Other parts that were discussed:\nThe high quality of the submitted projects and ’a worrying research waste: data that is neither used for publications nor shared.\nThe importance of placing the users – the community – at the center and addressing their real needs. In this respect, the Open Science Fund is a wonderful example of an innovative and pragmatic programme, which is sorely needed in the transition to open science.\nDiversity and Inclusion, Open Data Sharing and Re-use, Open Source Software, Rewards and Incentives for Open Science, Digital Infrastructure for Open Science, Open Reproducible Research, Community Building and Engagement.\n\n\n\nFigure 5: The NWO Open Science Meetup, June 24th 2022.\n\n\n\nJASP\nTogether with the highly popular JASP Statistics (https://jasp-statistics.org) we are further developing Raincloud Plots in their interface. JASP is the open-source alternative to the proprietary software SPSS. JASP offers both classical (i.e, frequentist) and Bayesian analysis methods. JASP has integrated Raincloud Plots last year, hotlink: https://jasp-stats.org/2021/10/05/raincloud-plots-innovative-data-visualizations-in-jasp/.\nCurrently, we are extending the visualization capabilities of JASP, by adding a covariate option, likert plot and multiple time point visualizations.\n\n\n\nFigure 6: You can read the full blogpost about Raincloud Plots in JASP here: https://jasp-stats.org/2021/10/05/raincloud-plots-innovative-data-visualizations-in-jasp/\n\n\n\nFinal remarks\nIf you have been using our framework over the past 4 years, we sincerely would like to thank you! If this is the first time you are reading about Raincloud Plots, we hope that it will be of use for you some day! We are working to constantly improve it and your feedback is greatly appreciated.\nOn behalf of the entire Raincloud Plots team, our best wishes for 2023.\nNicholas Judd, Jordy van Langen, Rogier Kievit\n\n\n\n",
    "preview": "posts/2023-03-23-rainclouds/fig1.png",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-16-Donders-Open-Science-Day/",
    "title": "Lowering Barriers to Entry: Reflections on the Donders Open Science Day 2022",
    "description": {},
    "author": [
      {
        "name": "Sam Parsons",
        "url": {}
      }
    ],
    "date": "2022-11-16",
    "categories": [],
    "contents": "\nOpen Science is the hip thing right now, confirmed our first speaker of the day, Dirk van Gorp. The Donders Session: Open Science Day certainly reinvigorated my enthusiasm for open science – and not just because it’s where all the cool kids hang out.\nWe (Fleur Zeldenrust, Sam Parsons, Rogier Kievit, and Laura de Nooij) wanted to showcase a wide range of useful tools and researchers’ experiences in Open Science. Seven speakers joined us in person, and remotely, across three broad sessions.\nIn the spirit of Open Science, recordings1 of the presentations and the slides are available here. The talks speak for themselves, but there were some key take-home messages and threads that ran neatly through the day.\n\n\n\nSession 1: “What is open science?”\nThere isn’t a clear answer, with “almost as many definitions as universities” (Dirk van Gorp). It was enlightening to hear about many initiatives happening at the Radboud – some behind-the-scenes, and others much more visible. The current policy initiatives look to help researchers make their work more Findable and Accessible. Dirk asked the audience who was familiar with the central Open Access policy, and only four hands were raised. This became a running theme of the event, there are many more impressive Open Science-related initiatives out there to learn about and benefit from. Making these initiatives and resources more visible is an important goal.\nSession 2: Our speakers introduced a bunch of useful tools\nGonny Kremers covered how to publish your work openly and the routes to open access, including Green (self-archiving), Gold (journal open access), and hybrid. Gonny shared important information for all Netherlands based researchers about Plan S and the Taverne Amendment. Understanding each is integral for all researchers funded by organisations that have signed Plan S, including NWO, ZonMw, and European Commission.\nPadraig Gleeson shared Open Source Brain, a platform for sharing and developing computational models of neural systems in an open and collaborative way. Open Neuroscience data, open models, and simulation tools are powerful, but to maximise their use, we need the computing infrastructure – Open Source Brain provides this. As Padraig said, and was echoed by almost every other speaker, “we want to lower the barrier for participation in science”.\nCaspar van Lissa introduced a Workflow for Open Reproducible Code in Science (WORCS), a tool to “lower the barrier of entry” into reproducible science. WORCS introduces an open and reproducible research workflow from the beginning of a project. It is built into an R package with github integration – which not only helps reproducibility but adds version control too. This has the benefit of making all of the tasks we usually remember at the last minute (share code, prepare data to share) easy and part of the natural workflow of a project.\n\n\n\nSession 3: Experiences of being an open scientist\nEmma Henderson shared her experience of doing only Registered Reports. For a Registered Report, authors submit a Stage 1 manuscript (introduction, methods, data analysis plan) to a journal for review. The manuscript is reviewed and accepted in-principle, before data are collected. Then, after the data are collected and analyses ran, the manuscript is accepted regardless of the results. This exciting format removes many forms of bias from the publication process, chiefly whether manuscripts are accepted based on significant results. The most common worry for students and their supervisors, interested in registered reports, is time. Emma’s response was clearly “I can make this work” – she completed three for her PhD Thesis. More than that, the review times Emma shared made many of us jealous compared to “traditional” peer review timelines.\nStephanie Forkel shared a smorgasbord of principles and practices of Open Science she uses with her collaborators: Use open tools (e.g. human connectome project, FSL, python), Share your data (e.g. neurovault, github, thingiverse, and Stephanie’s personal website), and make manuscripts open access (e.g. medRxiv, bioRxiv, Research Square, and more). In keeping with the spirit of the day, Stephanie discussed taking everyone else along and equitable access with the Neuroscience Alliance (NEURAL). To further discuss, engage, and communicate check out @CNSeminars; there are journal clubs, journal special issues, interviews, neuroimaging tutorials, movies, debates, and more. There are so many ways to get involved and benefit from Open Science that it can be overwhelming. But, don’t feel like you have to do everything – just find something that works for you.\nCoosje Veldkamp is a project manager of the YOUth Cohort Study. The study itself is super impressive, following nearly 4000 Dutch children throughout development from pregnancy into early adulthood. Added to this, YOUth is a trailblazer in Open Science: the data are FAIR (Findable, Accessible, Interoperable, Reusable) to allow other researchers to use them, they are harmonising these data with other large scale projects (including the Consortium on Individual Development). Coosje shared the vital behind-the-scenes innovation that was required to build and maintain this huge open longitudinal cohort. Finally, Coosje shared the sobering note that funding for YOUth will soon run out, which prompted some audience reflection on the importance of longer-term investment in important open science infrastructure projects.\nDiscussion: A day like this would not be complete without audience discussion and participation, and for our virtual attendees’ who doesn’t enjoy a break-out room discussion? Drawing on the Open Science as a buffet metaphor (Christina Bergman; read more here https://www.bps.org.uk/psychologist/bropenscience-broken-science) we discussed our own experiences, the kinds of open practices we want to try next, and the training we would need.\nThe practices that attendees were keen to adopt included sharing their data and code. We discussed sensitive data as a barrier to sharing, and that a viable work-around is to share simulated or synthetic data that share key statistical characteristics with the real data but are entirely anonymous. There were some fears around sharing code; what if my code is too messy? What if someone finds an error? In the end, we agreed that sharing messy code is still better - whether for others or for ourselves in the future - and at least if an error is found it can be corrected. Rounding off the discussion, we agreed that resources or training in code and data sharing would help alleviate some of these fears to help folk adopt more open practices. Perhaps for the next Donders Open Science day!\nAuthor: Sam Parsons\n\nThe recordings of the presentations are not available at the moment, but will be added soon.↩︎\n",
    "preview": "posts/2022-11-16-Donders-Open-Science-Day/open-science-Dirk_Sam.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-16-Null-Results-Are-Significant-Too/",
    "title": "Tell your students: Null results are significant too",
    "description": {},
    "author": [
      {
        "name": "Sam Parsons",
        "url": {}
      }
    ],
    "date": "2022-02-16",
    "categories": [],
    "contents": "\nWe all know that null (non-significant)1 results are informative, useful, and not at all a bad thing, right? Right…\nIn an entirely rigorous scientific approach to surveying peoples’ perspective of null results, I turned to statistics memes2. Just like academia, these memes neatly reflect the 5% alpha threshold: p < .05 and it’s publication party time, p > .05 and you cry a little.\n\n\n\nStudents often come face-to-face with their own personal null results towards the end of their research project. Usually the project is worth a good portion of their final grade and they feel the pressure to write a good report. When “good” includes some version of novelty or innovativeness, it’s understandable that they feel the pressure to “find something interesting” (read as: statistically significant) to discuss.\nSo, when the inevitable happens (p > .053), a path to the dark side emerges: Some students feel fear; what if they made a mistake or somehow ruined their study? Others feel anger, all they see are significant p values and supported hypotheses, why are they denied the right? Still more feel their burning hatred of statistics emerge again, born from a litany of frustrations throughout their training (not to mention math anxiety - see this twitter thread). Finally, many students feel suffering: at the loss of their favorite hypothesis, certainly that their training has given them little experience of describing and interpreting null results, and in feeling their “non-significant results give them nothing to write about”4.\nHonestly, I can’t blame them for feeling this way. The prevalence of Questionable Research Practices5 (e.g. Gopalakrishna et al. 2020) and the volume of student projects that “metamorphosize” from dull nulls into pretty supported results (e.g. O’Boyle et al. 2017) showcase that many established researchers embody the same reactions. Instead of focusing on this bleak outlook, we will keep our minds on supporting research students.\n\n\n\nA highly accurate, and well-sampled, representation of researchers’ responses to null results.\nMost supervisors will recognise any of the following from students’ null result papers:\nThe limitations clearly relate to not finding a significant effect. Sometimes the writing is explicit enough to state that fixing these limitations would help find significant effects.\nThey deploy the oft-used “approaching statistical significance”6 to allow them to discuss results through the more familiar lens of significant result. Again, to “have something to write about”.\nThe conclusions read as if nothing has been learned about the relationship between the variables, that the study itself was uninformative. Including the possibility that there is no true effect.\nConversely we found no effect, therefore no effect exists (and perhaps all the previous research was actually a massive false positive).\nI’ve often wondered how we can help our students and mentees. We can - and should - tell our trainees that a result does not have to be significant to be useful, or important, or “right”, and even publishable. But, however strongly we reinforce this, students are faced with overwhelming evidence to the contrary. Their own readings of the literature and every other subtle (or not subtle) message about new and exciting (significant) results we send them usually obliterates the message by the time they’re analyzing their hard collected data.\nHelping students\nInstead of sinking into an academic existential dread, here are two ways I have tried to help students overcome the dark side of null results (Warning: Your mileage may vary).\nFor several students a shallow dive into Bayes Factors7 and equivalence testing helped drastically. These projects included relatively simple models (e.g. in the realms of t-tests, correlations, and multiple regression) so the learning curve was not too steep. Thank you JASP for being an intuitive tool for students with minimal analyses and/or programming skills to run these analyses. My students were able to write that “the evidence favored the null model” instead of “we did not find a significant effect”, which seemed to empower them to “have something to talk about”. More than this, they had much more confidence in their interpretations of the study, even if that interpretation is that no hypothesis was better supported by the data.\nIn other student projects, we took to preregistration. Preregistration does not solve all problems (nor should it be expected to, or discussed as if it does), and much of this particular benefit could be achieved without any formal preregistration process. For us, and in more than one project, preregistration was a useful tool to explore several patterns of potential results and how we might interpret each one. It forced us to better consider the theory driving the study and how this interacted with our hypotheses and planned analyses (also see this nice blogpost for a similar non-preregistration argument). This did not entirely remove the sting when p > .058. But, those students were more capable of discussing the results in reference to the theory they were testing and the report did not read as if the study was worthless or uninformative.\nBroad improvements in the statistical training students undergo would also help. Whole communities have grown to support improving research training, for example a Framework for Open and Reproducible Research Training. But, waiting for the glacial pace of reforming curricula to catch up with our current needs gets old fast. Note, students likely don’t need more stats or more complex stats. Instead, they need more time dedicated to understanding how statistics work and how they can be used to make inferences.\nIn the meantime, I have a rapid-fire round of discussion points that have helped my students get to grips with interpreting nulls and hopefully feeling less hopelessness when they see p > .05[^And that clap of thunder makes three]. In no particular order, we could dedicate more time to; sampling variability and the dance of confidence intervals, meta analyses, what actually is a p value, effect sizes, open science, statistical power, common statistical misconceptions (Greenland et al., 2016), and that we should expect null effects in a line of studies even when the effect does exist (e.g. Lakens & Etz, 2017). Sharing papers reporting null results (maybe you have published your null results too?), gives students something tangible to grapple with other than being barraged by statistical significance. Avoiding valenced and judgemental language about results - “failed replications”, “failed experiments”, results are “negative” or “positive” - may help students feel more comfortable whatever the results. Finally, we can avoid preemptively making students feel they have missed a valuable opportunity by avoiding telling students that we might be able to publish the study “if we find something interesting”.\nConcluding remarks\nMost students have been told that their null results matter too, that null results tell us something. The often repeated phrase goes something like “even null results tell us something”. Often it feels like we are merely paying lip service to an idealized world of research and academic publishing. But, at the risk of sounding preachy, I believe that with consideration and more training we might create a world in which null results are not demonized and avoided, and instead added to the academic record to facilitate the scientific process. More immediately, maybe we can reduce some of our students’ p value anxiety.\nAuthor: Sam Parsons\nResources and links\nLakens, D., & Etz, A. J. (2017). Too true to be bad: When sets of studies with significant and nonsignificant findings are probably true. Social Psychological and Personality Science, 8(8), 875-881.\nGopalakrishna, G., Riet, G., Vink, G. Stoop, I., Wicherts, J., & Bouter, L. (2020). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: a survey among academic researchers in The Netherlands. https://www.nsri2020.nl/\nGreenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31(4), 337–350. https://doi.org/10.1007/s10654-016-0149-3\nO’Boyle Jr, E. H., Banks, G. C., & Gonzalez-Mulé, E. (2017). The chrysalis effect: How ugly initial results metamorphosize into beautiful articles. Journal of Management, 43(2), 376-399.\nReferences\nJASP Materials\nJASP Materials\nFramework for Open and Reproducible Research Training (FORRT)\nCyrussamii\nCoursera - Statistical Inferences\n\nSorry, Bayesians, this might not be for you↩︎\nCode for reproducibility check (https://www.google.co.uk/search?q=p+value+memes). You’re welcome, Open Science.↩︎\nCue thunder clap and ominous music↩︎\nAlmost a literal quote from more than one student↩︎\nOr Questionable Reporting Practices, depending on your personal preference↩︎\nFor other amusing examples from the published literature, see https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/↩︎\nSee, Bayesians, I hadn’t forgotten about you↩︎\nCue the second thunder clap↩︎\n",
    "preview": "posts/2022-02-16-Null-Results-Are-Significant-Too/null_results_Sam.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-17-What-Is-Parsimony-Worth/",
    "title": "What is parsimony worth?",
    "description": {},
    "author": [
      {
        "name": "Michael Aristodemou",
        "url": {}
      }
    ],
    "date": "2022-01-17",
    "categories": [],
    "contents": "\n\n\n\nIn the early 14th century, an English philosopher known as William of Ockham spoke thus: “pluralitas non est ponenda sine necessitate.” Centuries later the credo entities should not be multiplied without necessity has grown to be a universal principle, known as the principle of parsimony, which systematically biases decision making across the vast and varied scientific landscape. My introduction to this principle came during a statistics class when a senior student advised me that if I mention parsimony the department statisticians will do a little dance and award me an entire point on my assignment! Considering my main objective in life was to inflate my GPA, parsimony held a clear value. I’ve since graduated and parsimony has lost its point awarding abilities. Disappointingly, it also seems to have little effect on my supervisor’s dance tendencies. So, if parsimony cannot promote my personal goals, what is parsimony worth?\nParsimony in knowledge discovery\nThe definition of parsimony is by itself non-contentious to anyone who isn’t an avid supporter of redundancy. It also isn’t useful given that its value is context dependent. My interest lies in the domain of knowledge discovery and therefore this is the context in which parsimony will be evaluated. Let’s break down the definition and embed it into context: entities should not be multiplied without necessity. Our ultimate goal is to justify the should not part, that is to identify the utility of simplicity. To do this we first need to define the necessity. For without a target, we cannot judge when the “multiplication of entities” has to cease. Say we want to explain why people with sleep problems also experience fatigue and irritability. After we search for possible explanations, we want to select one—the best one ideally. So we need to compare our explanations, which means we need to transform them into something we can compare in terms of both accuracy and simplicity. One way to do this, is to express our theories as models and use some quantitative metric that reflects the extent to which they fit with our observations (e.g. the bayesian information criterion). We can call this model fit. Drawing from our example we can manufacture two quick-and-dirty theories: a) reciprocal causal associations between all three symptoms explain their co-occurrence; or, more “simply” b) a fourth variable (e.g., depression) causes all of them, which is why they co-occur. These explanations result in two models with different numbers of parameters. We can use the number of parameters needed to formalize an explanation to approximate its simplicity. Thus, we redefine our entities as the number of parameters needed to specify a given explanation. In the case that our models have the same fit, parsimony would dictate that we choose the simpler of the two—the more parsimonious model. Indeed, many metrics of model fit have an inbuilt penalty for the number of parameters a model has, making model fit the product of a trade-off between complexity and fit to the data1. The principle of parsimony can now be rephrased as: the number of parameters should not be multiplied further than is necessary to improve model fit. This brings us to the crux of the matter—why is this a good idea?\n\n\n\nFigure 1. Schematic of two example models one complex (Model A) and one simple (Model B)\nParsimony as bias\nIdeally, we want a model that fits both to our current observations but also fits well to independent samples. Otherwise, we run the risk of a model that fits tightly to random fluctuations in our data outperforming a model that better approximates the process of interest. This is commonly known as overfitting and is problematic since most real-world data reflects both the process of interest and sample-specific noise. To mitigate overfitting one can look at the generalization error, which indicates how well a model performs in a previously unseen sample. The rationale being that if a model performs well on a given dataset because it fits well to the sample-specific noise, then it should do poorly when fitted to another sample. While a model that fits well to the process of interest should fit well to all samples that appropriately measure that process. A common justification for choosing the most parsimonious model is that it will always minimize generalization error. Which brings us to a popular definition of parsimony: the simpler of two models with equal fit on a given dataset, will fit better on unseen datasets. This statement when taken literally is false. The falsity of this statement follows from David Wolpert’s “no free lunch” theorem2. What the “no free lunch” theorem shows is that for any pair of models there are as many domains where the simpler model is preferable as there are domains where the more complex model is preferable. This essentially invalidates the universality of simplicity as a guiding tool for model selection—in fact for any two models A and B there are as many domains where model A has lower generalization error as there are domains where this is true for model B. The more interesting question, however, isn’t whether parsimony guarantees lower generalization error. What is practically interesting is whether the use of parsimony will lead to lower generalization error in most (or all) applied situations. Domingos follows this precise question in an extensive review of empirical circumstances that contradict this weaker justification for parsimony3. Specifically, he shows that within the domain of machine learning simpler models often lead to higher generalization error. Therefore, both empirically and mathematically the claim that parsimony leads to lower generalization error is found wanting.\nSimplicity and comprehensibility\nSo what if parsimony doesn’t buy us more accurate predictions? Arguably a worthwhile cost if our main aim is to understand the world and simpler models are easier to comprehend. But what makes a model more comprehensible? In 2006, van der Maas and colleagues, debuted their theoretical alternative to the dominant g-factor model that presented a single entity as the causal driver of intelligence—much like our fictitious model B (Figure 1). The mutualism model, as van der Maas termed it, is much more complex in terms of parameters than the g-factor model and fits just as well to cross-sectional observations. If we use comprehensibility as a tie-breaker we should be safe betting on the more parsimonious model. Not so fast. Simplicity in terms of the effective number of parameters needed to specify the g-factor model does not reflect its comprehensibility. As van der Maas argues, the mutualism model certainly can multiply the number of parameters, but the g-factor model conjures up “a rather mysterious” hidden variable4. The same can be said for our toy models. Model B buys its simplicity by manufacturing an entirely new, arguably opaque entity, while model A presents a more complex mechanism that nevertheless is easier to comprehend. In other words, we can better intuit how sleeplessness might make one tired and therefore irritable, while it is harder to parse what this depression variable actually is and how it brings symptoms to be. It seems that parsimony also fails to guarantee superior comprehensibility in some domains.\nParsimony in model search\nIt seems not even parsimony suffices as a fast-and-hard rule that we can generously apply to any domain of science. But there is one domain where parsimony may still be unequivocally welcome. This is the domain of model search. Blumer showed mathematically that the more models we test on our data, the greater the chance that the best fitting model will fit poorly on other samples5. This is essentially multiple testing in model search and reflects the fact that testing more models increases the probability that we find a good fitting model purely by chance.\nDomingos presents an accessible overview of the mathematical argumentation in his review. It goes something like this. Let’s say that the generalization error of a hypothesis is greater than ε. From this it follows that the probability that our hypothesis is correct on x number of independent samples is smaller than (1 — ε)x[^ refers to the power of, e.g. 2^2 = 4. Our cutting-edge editor does not have superscript functionality.]. If we consider n number of hypotheses then the probability that at least one of them is correct in all x independent samples is n(1 — ε)^x. If we substitute this with real numbers, we can see that the probability of at least one of our hypotheses being correct increases with the number of hypotheses considered. That is 2(1 — 4)^2 is 18, which is smaller than 4(1 — 4)^2 which is 36. In a nutshell6, “if we select a sufficiently small set of models prior to looking at the data, and by good fortune one of those models closely agrees with the data, we can be confident that it will also do well on future data.7” Hence, multiple testing provides a safe-haven for the historic concept of parsimony, but veers from the traditional interpretation of parsimony as it pertains to the assumptions within an explanation.\nGoodbye parsimony\nThroughout my reading for this blog, I had to bury my naive belief in the powers of parsimony. That’s strike two. Now I will be forced to constrain my models in another way. Through the grind of gaining domain knowledge and thoughtfully integrating it into the a priori specification of my models. This currently seems like the only effective recourse to reduce the number of models tested and improve comprehensibility. Thanks for the points parsimony, you’ve gotten me this far…\nAuthor: Michael Aristodemou\n\nThis can lead to situations where parsimony leads us to choose the simpler model with worse fit to the data. Meaning parsimony is not just a tie-breaker.↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\nVan Der Maas, H. L., Dolan, C. V., Grasman, R. P., Wicherts, J. M., Huizenga, H. M., & Raijmakers, M. E. (2006). A dynamical model of general intelligence: the positive manifold of intelligence by mutualism. Psychological review, 113(4), 842.↩︎\nBlumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. (1987). Occam’s razor. Information Processing Letters, 24, 377(380).↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\nWolpert, D. H. (1996). The lack of a priori distinctions between learning algorithms. Neural computation, 8(7), 1341-1390.↩︎\n",
    "preview": "posts/2022-01-17-What-Is-Parsimony-Worth/Overfitting_Michael.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-29-Working-from-home/",
    "title": "Working from home or living at work?",
    "description": {},
    "author": [
      {
        "name": "Rogier Kievit",
        "url": {}
      }
    ],
    "date": "2021-11-29",
    "categories": [],
    "contents": "\n\n\n\nFriday March 6 2020 was the last day I went to my former workplace in Cambridge, UK. As we have a child who is especially vulnerable to viral illness, we decided, well before it was ‘en vogue’, to stay at home. We received rather ominous letters about us not being allowed to leave the house at all – shortly followed by more reassuring letters that ‘opening a window was allowed’.\nWhat many hoped would be a brief period of atypical working arrangement soon stretched to something closer to two years, and is sadly far from over. Never before have our daily work habits changed so fundamentally in such a short period of time, and the same is true for scientists. Conferences with thousands of participants became completely virtual. Lectures were commonly characterized by vast, silent plains of black squares. One is perhaps best off assuming the silence reflects a breathlessly listening audience. In the entire first year in my new post at the Donders institute I was only able to work in person a handful of times – the rest meant (re)starting a new lab in a new country from the kitchen table (not to mention buying a new house through videochat from a different country – but that’s another story). Although, unfortunately, the pandemic is far from over, we can certainly take stock of the many and rapid changes, and reflect on some of the lessons learned.\nThe Bad1\nThe challenges were, and are, many. For instance, working from home with (young) children is often almost impossible - the combination of acting as a teacher at home and at the same time juggling work responsibilities is, to put it mildly, not ideal. This is especially true for the most exciting parts of our work that demand deep thinking and reflection – Something not particularly compatible with simultaneously assisting in the construction of ambitious cardboard castles, tending to snail collections and home ‘baking’. Of course, the challenges for scientists living alone, especially those away from their home or country of origin, are distinct, but no less challenging.\nScientifically, one of the key drawbacks is the lack of casual, unplanned conversations at the coffee machine. These informal contacts prove not only essential as a ‘social glue’, but also as the origin of many new ideas, contacts and collaborations. As good as Zoom and team meetings have become in terms of the core business of sharing talks and slides, they generally fail at the hard-to-explain intellectual chemistry that arises from serendipitous in-person encounters. This is especially problematic for early career researchers, who build up their social and academic networks through these chance encounters. We try our best to replicate such encounters online, but the best we can do is to approximate them – or to hope to develop new strategies to foster them.\nAlthough the reduction of commuting time entails the clear benefit of ‘more hours in the day’, it comes with other, more psychological challenges. When I drop off my daughter in the morning and am working from home, I can be behind my desk a minute later. This sometimes whiplash inducing switch between parenting and work mode is something that takes time to master. A related challenge exists at the other end of the day – When does working from home turn to living at work? It can be overly tempting to continue working at that same kitchen table during dinner preparation, and/or well into late hours (recent research has shown workdays up to 2 hours longer for those working from home ). For long term maintenance of high level ‘deep work’ it is crucial we find rituals that allow a clear(er) division of work and free time, so that we work from home rather, than live at work, in ways sustainable in the long term. We’ve found some value in the advice and strategies in Cal Newport’s ‘Deep Work’, but many other approaches exist.\nThe Ugly\nUndoubtedly one of the ‘ugliest’ features of this pandemic is that it amplifies pre-existing inequities. Several analyses have demonstrated that the adverse consequences for scientific productivity have been especially pronounced for, among others, working parents, especially mothers, of young children2 and/or people of colour right at a career point where the proverbial pipeline is at its leakiest. As a field, we have to try our very best to consider the differential impact of these challenges at any opportunity we have, to try to adjust for the pronounced pandemic disparities.\nThe Good\nThere are, of course, also positive things to come out of our changed work habits. The ability to work remotely and flexibly, requested by people with disabilities of various kinds for decades, turned out to be quite possible once it was needed by a sufficiently large enough group of people. The decrease in commute time means that an efficient day working at home can simultaneously be more productive for work and family/leisure time – a potential win-win. And as challenging as working from home with homeschooling children has been and continues to be, it is also undoubtedly wonderful to be around them (even) more. Personally, I’ve embraced the two most cliched lockdown activities: Learning how to bake sourdough and running further than ever before, both of which are here to stay.\nAnother benefit is that it has become more commonplace to invite speakers from all over the world to small and large gatherings, bringing greater diversity in backgrounds and topics. Since last year we regularly invite the authors of papers in our journal clubs to join part or all of the conversation, hugely enriching the depth of our reading and understanding.\nHybrid and online working have become almost (but not quite) seamless, and meetings that should be zoom calls often are. I think back with some amazement and no real nostalgia at certain meetings where 20 very busy people would commute to a single location, for only 2-3 central people to speak the entire time. Similarly, the realisation that the cost in terms of CO2 and time away from loved ones for conferences at the very least means we should substantially decrease the frequency of academic activities that involve long distance travel3. In theory, this will ultimately allow a more diversified set of conferences where you can attend the majority hybrid or online, yet benefit from the very real added value of in person conferences for a subset. An added benefit of the virtual conference format is that the chat Q&A can be a great leveler - I have noticed that conference questions in chat format often come from a more diverse, more early career scientists, and are often all the more insightful, knowledgeable and creative for it.\nHow we’re trying to make it work\nAt the Donders institute, we are actively trying to learn from the recent past to improve the present as well as the more distant future. Many research groups and scientists from all backgrounds and seniorities have tried out a vast array of creative solutions – Zoom tea breaks, shut up and write sessions, gathertowns, lab walks and elaborate games, and share what works and what doesn’t. One thing my lab has initiated since the more recent tightening of restrictions has been the early morning scrum/rollcall/huddle4: Very brief (5 minute) meetings where everyone outlines their plans and we get to see everyone’s face on a more regular basis. Not only is it nice to see everyone in 2D, if not in reality, but voicing your plans for the day out loud has a surprisingly large beneficial effect on one’s productivity. Similarly, it took a while for me to be convinced of the benefits of Slack, but now that it has become fully integrated it is the virtual heart of the lab – Quick chats and meetings, a steady stream of interesting papers and resources, and attempts to decipher Dutch customs, including stroopwafel etiquette, in our #undutchables channel has become an indispensable part of the lab. Of course, all of the above is from my narrow and rather specific set of circumstances – I’d love to hear from you about challenges I have overlooked, as well as strategies that have worked well (or failed spectacularly).\nThe motto of my former Cambridge College (Fitzwilliam College) is ‘The best of the old and the new’. As we navigate our way through ebbing and flowing Covid waves towards a future version of academic work, I can only hope we take this motto to heart. Revive what we miss whenever possible, and embrace the new opportunities that arise.\nAuthor: Rogier Kievit\n\nThis blogpost is about the consequences of the pandemic for (academic) work, not the pandemic itself, but of course the single largest consequence of the pandemic is direct: (severe) illness and death for many, heartbreak for family, and exhaustion and burnout for care workers.↩︎\nhttps://www.nap.edu/catalog/26061/the-impact-of-covid-19-on-the-careers-of-women-in-academic-sciences-engineering-and-medicine & https://www.nature.com/articles/d41586-021-03045-w↩︎\ne.g. see https://academicflyingblog.wordpress.com/↩︎\nPlease select your least favourite term.↩︎\n",
    "preview": "posts/2021-11-29-Working-from-home/lockdown_Rogier.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-14-I-Am-Quant/",
    "title": "I am Quant (and so can you!): Seriously",
    "description": {},
    "author": [
      {
        "name": "Ethan McCormick",
        "url": {}
      }
    ],
    "date": "2021-10-14",
    "categories": [],
    "contents": "\n\n\n\nI’m sure that I am not the only one who has sat in many a conference hall (imagine back through the mists of times to those days), listening to talks and wondering “How am I ever going to be that smart/knowledgeable about [insert just about anything here]?”. As a first-year graduate student, it is perhaps unsurprising that I would feel that way. I had many years ahead of me to gain the knowledge and skills that those speakers had. All those years later, and now I’m officially “Dr. McCormick”, even though only one person ever calls me that (more on him later). However, that feeling doesn’t just go away. I regularly see a talk or read a new paper/preprint and think “Well damn, when am I going to have time to learn this?”. This has especially been true as I have attempted to pivot my research program from one aimed at addressing substantive questions regarding the brain-based changes that driving learning to one focused on studying and developing the quantitative methods we use to understand change over time (i.e., longitudinal models). I am hardly the only one who has felt the lure of advanced methods from more substantive research fields. I came of age in research during a time with a much greater focus on rigorous methods, open science, and reproducibility/replication. Many researchers in my cohort are motivated like never before to incorporate more rigorous methods from statistics and data science into their own work. However, many also find these methods intimidating. After all, how do I know that I’m using them correctly? I have been incredibly fortunate along the way to have had amazing mentors and a bit of luck in learning new methods. Here I will lay out some tips and tricks I have picked up along the way. So, if you are hoping to transition in a major way to quantitative methods, or just hoping to get better estimates for your research questions, hopefully these can help you on your way.\nTake a Course\nI know that in the age of the internet, we are all supposed to be DIYing it towards ultimate knowledge and expertise in whatever subject we take up. I have been able to use online resources to refine skills, or dive into advanced subjects, but I am not made of stern enough stuff to learn structural equation models by my little lonesome at night at my computer reading Bollen, 1989 (although I do recommend that book in the highest terms). Some sort of structured course is incredibly valuable for getting the basics under your belt, which you can then build on independently later. Of course, needing to take a formal course might be a real impediment (especially if they cost money) since not everyone is a graduate student in a quant-heavy institution. Here, some sort of online course or video series may be a great alternative, but the key is to structure it like a course, where you have periodic checks of your understanding and a committed time. Unfortunately, my intention to learn computational modeling in the evenings wasn’t successful until I registered for a course and was expected to show up every week. One free resource people might consider is the podcast Quantitude, where two quantitative faculty talk about a range of topics. It’s not systematic like a course would be, but it’s an amazing resource for those hoping to learn more about specific topics in a fun way.\nFind a Quantitative Person to Pester\nThis is only said partly in jest. When I took quant courses at UNC Chapel Hill, I frequently wanted to chase down offhanded comments by the professors. After a couple weeks of gathering my courage, I set up a meeting with them and basically came with a list of questions. This felt incredibly presumptuous and like I was wasting their time at first, but ultimately, I got more out of those conversations than I will ever be able to count. Not only did I learn more than I would have otherwise about the methods I use every day in my own research then, but those conversations also became the ideas behind manuscripts I am writing now. Like anyone, quant people love to talk about their research with an interested student, and they probably get to do it less often than others. I can’t promise that every quantitative methodologist is as lovely as the ones I have known, and time constraints are real, but you’d be surprised how many of them do want to be pestered by interested students looking to dive into advanced methods past the basic coursework.\nAsk Questions…so many questions\nThis is something I have to remind myself of even now. There is a lot of pressure to appear like you understand something (we’ve all been and seen the nodding heads in class), but there are so many things to know and the best way to accumulate them is to constantly be asking questions when you don’t understand. This also applies to professional development. I came to quant relatively late in my graduate training, but once I developed some relationships with quantitative faculty in my department, I started asking questions like “Do you think this would be a good idea for a paper?” and “Would you be willing to write a training grant with me?” I have found that the people in my career have been incredibly generous with their time and energy.\nThere is No Secret Sauce\nIf anything can be learned from my career trajectory, it’s that there is no hidden secret to getting into quantitative methods. You don’t need to be a math savant (I’m certainly not) and the new generation of methodologists is shaking off the remnants of the “old boys” club culture that was prevalent in prior decades, although much work remains to be done in that direction. Basically, I had the great fortune to study at UNC Chapel Hill with faculty like Ken Bollen, and Dan Bauer, and Patrick Curran. I was excited by what I was learning and so started to haunt the offices of Dan and Patrick. This has not only led to great mentor relationships with great researchers, but also a considerable shift in my program of research. Now instead of being the student, I help run courses and workshops in quantitative methods. If I can do it, so can you. Welcome to the quant side, we have cookies!\nAuthor: Ethan McCormick\n\n\n\n",
    "preview": "posts/2021-10-14-I-Am-Quant/Quant_Ethan.jpg",
    "last_modified": "2025-07-03T09:10:21+02:00",
    "input_file": {}
  }
]
